{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 28, 28])\n",
      "Size of training dataset: 60000\n",
      "Size of test dataset: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Image size: {training_data[0][0].shape}\")\n",
    "print(f\"Size of training dataset: {len(training_data)}\")\n",
    "print(f\"Size of test dataset: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(10),  # 10 classes in total.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/07 14:47:08 INFO mlflow.tracking.fluent: Experiment with name '/mlflow-pytorch-quickstart' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/807520117673243129', creation_time=1715086028459, experiment_id='807520117673243129', last_update_time=1715086028459, lifecycle_stage='active', name='/mlflow-pytorch-quickstart', tags={}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/mlflow-pytorch-quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, metrics_fn, optimizer, epoch):\n",
    "    \"\"\"Train the model on a single pass of the dataloader.\n",
    "\n",
    "    Args:\n",
    "        dataloader: an instance of `torch.utils.data.DataLoader`, containing the training data.\n",
    "        model: an instance of `torch.nn.Module`, the model to be trained.\n",
    "        loss_fn: a callable, the loss function.\n",
    "        metrics_fn: a callable, the metrics function.\n",
    "        optimizer: an instance of `torch.optim.Optimizer`, the optimizer used for training.\n",
    "        epoch: an integer, the current epoch number.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        accuracy = metrics_fn(pred, y)\n",
    "\n",
    "        # Backpropagation.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            step = batch // 100 * (epoch + 1)\n",
    "            mlflow.log_metric(\"loss\", f\"{loss:2f}\", step=step)\n",
    "            mlflow.log_metric(\"accuracy\", f\"{accuracy:2f}\", step=step)\n",
    "            print(f\"loss: {loss:2f} accuracy: {accuracy:2f} [{current} / {len(dataloader)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, loss_fn, metrics_fn, epoch):\n",
    "    \"\"\"Evaluate the model on a single pass of the dataloader.\n",
    "\n",
    "    Args:\n",
    "        dataloader: an instance of `torch.utils.data.DataLoader`, containing the eval data.\n",
    "        model: an instance of `torch.nn.Module`, the model to be trained.\n",
    "        loss_fn: a callable, the loss function.\n",
    "        metrics_fn: a callable, the metrics function.\n",
    "        epoch: an integer, the current epoch number.\n",
    "    \"\"\"\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            eval_loss += loss_fn(pred, y).item()\n",
    "            eval_accuracy += metrics_fn(pred, y)\n",
    "\n",
    "    eval_loss /= num_batches\n",
    "    eval_accuracy /= num_batches\n",
    "    mlflow.log_metric(\"eval_loss\", f\"{eval_loss:2f}\", step=epoch)\n",
    "    mlflow.log_metric(\"eval_accuracy\", f\"{eval_accuracy:2f}\", step=epoch)\n",
    "\n",
    "    print(f\"Eval metrics: \\nAccuracy: {eval_accuracy:.2f}, Avg loss: {eval_loss:2f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/lsms/lib/python3.9/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "metric_fn = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "model = ImageClassifier().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305250 accuracy: 0.078125 [0 / 938]\n",
      "loss: 2.193538 accuracy: 0.375000 [100 / 938]\n",
      "loss: 1.938535 accuracy: 0.531250 [200 / 938]\n",
      "loss: 1.619792 accuracy: 0.609375 [300 / 938]\n",
      "loss: 1.141457 accuracy: 0.671875 [400 / 938]\n",
      "loss: 0.965002 accuracy: 0.687500 [500 / 938]\n",
      "loss: 0.929441 accuracy: 0.734375 [600 / 938]\n",
      "loss: 0.767638 accuracy: 0.796875 [700 / 938]\n",
      "loss: 0.799206 accuracy: 0.718750 [800 / 938]\n",
      "loss: 0.814684 accuracy: 0.734375 [900 / 938]\n",
      "Eval metrics: \n",
      "Accuracy: 0.74, Avg loss: 0.749914 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.709095 accuracy: 0.796875 [0 / 938]\n",
      "loss: 0.793277 accuracy: 0.687500 [100 / 938]\n",
      "loss: 0.528323 accuracy: 0.828125 [200 / 938]\n",
      "loss: 0.788145 accuracy: 0.718750 [300 / 938]\n",
      "loss: 0.705893 accuracy: 0.640625 [400 / 938]\n",
      "loss: 0.678194 accuracy: 0.796875 [500 / 938]\n",
      "loss: 0.714105 accuracy: 0.718750 [600 / 938]\n",
      "loss: 0.640365 accuracy: 0.812500 [700 / 938]\n",
      "loss: 0.689241 accuracy: 0.750000 [800 / 938]\n",
      "loss: 0.674569 accuracy: 0.765625 [900 / 938]\n",
      "Eval metrics: \n",
      "Accuracy: 0.76, Avg loss: 0.654315 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.581902 accuracy: 0.781250 [0 / 938]\n",
      "loss: 0.650557 accuracy: 0.703125 [100 / 938]\n",
      "loss: 0.451051 accuracy: 0.843750 [200 / 938]\n",
      "loss: 0.704818 accuracy: 0.734375 [300 / 938]\n",
      "loss: 0.670275 accuracy: 0.687500 [400 / 938]\n",
      "loss: 0.632499 accuracy: 0.812500 [500 / 938]\n",
      "loss: 0.650506 accuracy: 0.750000 [600 / 938]\n",
      "loss: 0.631631 accuracy: 0.796875 [700 / 938]\n",
      "loss: 0.699677 accuracy: 0.734375 [800 / 938]\n",
      "loss: 0.595999 accuracy: 0.765625 [900 / 938]\n",
      "Eval metrics: \n",
      "Accuracy: 0.76, Avg loss: 0.631153 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    params = {\n",
    "        \"epochs\": epochs,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": 64,\n",
    "        \"loss_function\": loss_fn.__class__.__name__,\n",
    "        \"metric_function\": metric_fn.__class__.__name__,\n",
    "        \"optimizer\": \"SGD\",\n",
    "    }\n",
    "    # Log training parameters.\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log model summary.\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, metric_fn, optimizer, epoch=t)\n",
    "        evaluate(test_dataloader, model, loss_fn, metric_fn, epoch=0)\n",
    "\n",
    "    # Save the trained model to MLflow.\n",
    "    mlflow.pytorch.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = f\"runs:/{run.info.run_id}/model\"\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = loaded_model.predict(training_data[0][0][None, :].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
